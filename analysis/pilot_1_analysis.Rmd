---
title: "Pilot 1 Analysis"
author: "Bonan"
date: "8/12/2021"
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
---

```{r packages, include=FALSE}
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
library(patchwork)
library(knitr)
library(googlesheets4)
```

```{r data, include=FALSE}
load('data/pilot_1_cleaned.rdata')
# Rename conditions
df.sw = df.sw %>%
  mutate(condition=case_when(condition=='comp_const'~'combine', 
                   condition=='comp_mult'~'construct', 
                   condition=='comp_mult_reverse'~'discern'))
df.tw = df.tw %>%
  mutate(condition=case_when(condition=='comp_const'~'combine', 
                   condition=='comp_mult'~'construct', 
                   condition=='comp_mult_reverse'~'discern'))
# Label data
labels = read_sheet("https://docs.google.com/spreadsheets/d/1xmfK-JrVznHkPfKPoicelXOW5Mj252G2TtY6O9PP2tM/edit#gid=1386715201")
labels = labels  %>%
  mutate(condition=case_when(condition=='comp_const'~'combine', 
                   condition=='comp_mult'~'construct', 
                   condition=='comp_mult_reverse'~'discern'))

```


# Experiment

## Materials

In this experiment we have:

- Agent object properties: number of stripes and dots (randomly positioned).
- Recipient object properties: number of blocks.
- Result object properties: number of blocks.
- Animation: an agent object moves towards a recipient object, and the recipient object changes into the result form by varying its original number of blocks.
- **Ground-truth** rule is a mixture of multiplication and subtraction: `Blocks(R') <- Stripes(A) * Blocks(R) - Dots(A)`.

And three **learning conditions**:

1. `Construct`: First build the `Stripes(A) * Blocks(R)` sub-part, and then re-use it to build the ground truth rule
  ![](figs/construct.png)

2. `Discern`: reverse order of the `construct` condition
  ![](figs/discern.png)

3. `Combine`: First build the `Stripes(A) * Blocks(R)` sub-part, and then build the `- Dots(A)` sub-part
  ![](figs/combine.png)



**Generalization trials** are picked by a mixture of novelty & EIG re. potential causal rules.
Their orders were randomized for every participant.

* ![](figs/gen_trials.png) 



## Procedure

Each participant is randomly assigned to one of the three learning conditions. After reading instructions and passing a comprehension quiz, they first watched three learning examples, and then were asked to write down their guesses about the underlying causal relationships & made generalization predictions for eight pairs of novel objects. 
After that, they watched another three learning examples, and then wrote down an updated guess and made 8 generalization predictions. 
The pairs of generalization objects in both phases are the same, but their presentation orders were randomized.
All learning examples were remained in the screen once they had appeared.
Generalization trials appeared sequentially, and once a prediction was made the trial was replaced by the next one.




# Pilot results


Recruited N = 20 participants on Prolific (age = `r round(mean(df.sw$age))` ± `r round(sd(df.sw$age),1)`). 

Mean time spent `r round(mean(df.sw$instructions_duration+df.sw$task_duration)/60000,2)` minutes.

Base payment is £1.20, 
and bonus are paid for both free-responses (£0.20 per input, 2 inputs in total) and generalization predictions (£0.05 per correct one with respect to ground-truth).


```{r condition_sum, echo=FALSE}
overview = df.sw %>% 
  group_by(condition) %>%
  summarise(n=n(), 
            age=round(mean(age)),
            intro_time=round(mean(instructions_duration)/60000,2),
            task_time=round(mean(task_duration)/60000,2), 
            difficulty=round(mean(difficulty),2),
            engagement=round(mean(engagement),2)
            )
kable(overview, caption = 'Overview (cells are mean values, time in minutes, difficulty & engagement scales are 1-10)')
```


## Task difficulty

Participants in the `discern` condition took the longest time to finish the task, and reported the highest self-evaluated difficulty as well. Participants in the other two conditions, where sub-parts were built before seeing complex examples, took less time to finish the task and reported lower difficulty evaluations.


```{r condition_plot, echo=FALSE}
sum_data=df.sw %>% 
  group_by(condition) %>%
  summarise(task_time=mean(task_duration)/60000, 
            difficulty=mean(difficulty)) %>%
  ungroup()
  
ggplot(sum_data, aes(x=condition)) +
  geom_bar(aes(y=task_time), stat='identity', fill='#69b3a2') +
  geom_line(aes(y=difficulty, group=1), linetype='dashed') +
  geom_point(aes(y=difficulty), size=2) +
  scale_y_continuous(
    name='Minutes',
    sec.axis=sec_axis(~./1.2, name='Scales (10=very hard)')
  ) +
  labs(x='', title = 'Average task time (bars) and self-evaluated difficulty (dots)') +
  theme_bw()

```



## Free responses

Below are plots of the change in the free response guesses in Learning phase A and Learning phase B.

For the `construct` condition (green line), certainty was very high in Learning phase A (when dots are set to 0), and dropped after Learning phase B. The length of texts stayed roughly the same.

For the other two conditions, certainty was low in Learning phase A, and increased after watching the second batch of examples. Accordingly, text inputs were lengthy in Learning phase A, indicating more rambling and guessing, and became a lot more succinct in Learning phase B. This trend is especially clear for the `discern` condition. We can do further labeling on these texts for more fine-grained analysis.


```{r phases, echo=FALSE}
sum_phase=df.sw %>%
  mutate(len_a=str_length(input_a), len_b=str_length(input_b)) %>%
  group_by(condition) %>%
  summarise(certainty_a=mean(certainty_a), certainty_b=mean(certainty_b),
            input_a_length=mean(len_a), input_b_length=mean(len_b))

cert <- sum_phase %>%
  gather(measure, value, certainty_a, certainty_b, input_a_length, input_b_length) %>%
  filter(substr(measure,1,1)=='c') %>%
  mutate(measure=toupper(substr(measure, 11, 11))) %>%
  ggplot(aes(x=measure,y=value,group=condition)) +
  geom_line(aes(color=condition),linetype="dashed", size=1.2) +
  geom_point(aes(color=condition, shape=condition), size=3.5) +
  labs(x='', y='', title='Certainty') +
  theme_bw()

len <- sum_phase %>%
  gather(measure, value, certainty_a, certainty_b, input_a_length, input_b_length) %>%
  filter(substr(measure,1,1)=='i') %>%
  mutate(measure=toupper(substr(measure, 7, 7))) %>%
  ggplot(aes(x=measure,y=value,group=condition)) +
  geom_line(aes(color=condition),linetype="dashed", size=1.2) +
  geom_point(aes(color=condition, shape=condition), size=3.5) +
  labs(x='', y='', title='Input length (nchar)') +
  theme_bw()

combined = cert + len & theme(legend.position = "bottom")
combined + plot_layout(guides = "collect")
```




## Learning accuracy

In all three conditions, prediction accuracy (according to strict comparison with ground truth) increased after seeing more examples. 
Nevertheless, participants in the `construct` condition got the most predictions correct.

As for self-reports, accuracy in the `construct` condition stays with same, while the other two shows improvement. 
In Learning phase B, participants in the `combine` condition shows highest accuracy in their self-reports, while their prediction accuracy is worse than the `construct` condition. This indicates that getting the correct sub-parts are not enough for making generalization predictions - how to combine them also matters.


```{r accuracy, echo=FALSE, message=FALSE}
pred_acc = df.tw %>%
  group_by(batch, condition) %>%
  summarise(acc=sum(correct)/n()) %>%
  ggplot(aes(x=batch,y=acc,group=condition)) +
  geom_line(aes(color=condition),linetype="dashed", size=1.2) +
  geom_point(aes(color=condition, shape=condition), size=3.5) +
  labs(x='', y='', title='Prediction accuracy (strict)') +
  ylim(0,0.75) +
  theme_bw()


report_acc = labels %>%
  select(ix, condition, input_a_correct, input_b_correct) %>%
  gather(phase, correct, input_a_correct, input_b_correct) %>%
  mutate(phase=toupper(substr(phase,7,7))) %>%
  group_by(condition, phase) %>%
  summarise(acc=sum(correct)/n()) %>%
  ggplot(aes(x=phase, y=acc, group=condition)) +
  geom_line(aes(color=condition),linetype="dashed", size=1.2) +
  geom_point(aes(color=condition, shape=condition), size=3.5) +
  labs(x='', y='', title='Self-report accuracy') +
  ylim(0,0.75) +
  theme_bw()

acc_combined = pred_acc + report_acc & theme(legend.position = "bottom")
acc_combined + plot_layout(guides = "collect")

```











